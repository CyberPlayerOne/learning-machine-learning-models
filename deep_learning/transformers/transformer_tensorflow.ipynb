{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/text/tutorials/transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-29 12:34:46.363343: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-29 12:34:46.533035: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-09-29 12:34:47.740653: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-09-29 12:34:47.740728: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-09-29 12:34:47.740735: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data handling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Download the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-29 12:56:30.205994: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1mDownloading and preparing dataset 124.94 MiB (download: 124.94 MiB, generated: Unknown size, total: 124.94 MiB) to ~/tensorflow_datasets/ted_hrlr_translate/pt_to_en/1.0.0...\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "Dl Completed...: 0 url [00:00, ? url/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "57d74b21e13b4c19bb8fc40001410dc1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Dl Size...: 0 MiB [00:00, ? MiB/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "236f373fd10e41459f094575e521f4eb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Extraction completed...: 0 file [00:00, ? file/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8728eb1d2a6e4917adce984ea49fda5e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating splits...:   0%|          | 0/3 [00:00<?, ? splits/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cd3549ef1c1a43ad9d9e1bbd7eea08c6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating train examples...:   0%|          | 0/51785 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "302c30ce1a36418584ee1b372bd74099"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Shuffling ~/tensorflow_datasets/ted_hrlr_translate/pt_to_en/1.0.0.incompleteTT9Z48/ted_hrlr_translate-train.tf…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8dcbce4f41b54dec904a08d96592c016"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating validation examples...:   0%|          | 0/1193 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "59ec032b295449bfb9c96bd4b5be3832"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Shuffling ~/tensorflow_datasets/ted_hrlr_translate/pt_to_en/1.0.0.incompleteTT9Z48/ted_hrlr_translate-validati…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e92be55853aa4f64a17984ac0f038dd1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating test examples...:   0%|          | 0/1803 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8a3a171683d54a1683ab4f982564998b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Shuffling ~/tensorflow_datasets/ted_hrlr_translate/pt_to_en/1.0.0.incompleteTT9Z48/ted_hrlr_translate-test.tfr…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "be939c82521440e09086f76afa1940dd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1mDataset ted_hrlr_translate downloaded and prepared to ~/tensorflow_datasets/ted_hrlr_translate/pt_to_en/1.0.0. Subsequent calls will reuse this data.\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-29 12:57:36.870676: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-29 12:57:37.461223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-29 12:57:37.462632: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-29 12:57:37.465876: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-29 12:57:37.467378: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-29 12:57:37.468856: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-29 12:57:37.470633: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-29 12:57:37.952003: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-29 12:57:37.952324: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-29 12:57:37.952595: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-29 12:57:37.952854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6369 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en',\n",
    "                               with_info=True,\n",
    "                               as_supervised=True)\n",
    "\n",
    "train_examples, val_examples = examples['train'], examples['validation']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Examples in Portuguese:\n",
      "e quando melhoramos a procura , tiramos a única vantagem da impressão , que é a serendipidade .\n",
      "mas e se estes fatores fossem ativos ?\n",
      "mas eles não tinham a curiosidade de me testar .\n",
      "\n",
      "> Examples in English:\n",
      "and when you improve searchability , you actually take away the one advantage of print , which is serendipity .\n",
      "but what if it were active ?\n",
      "but they did n't test for curiosity .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-29 13:00:11.771914: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for pt_examples, en_examples in train_examples.batch(3).take(1):\n",
    "  print('> Examples in Portuguese:')\n",
    "  for pt in pt_examples.numpy():\n",
    "    print(pt.decode('utf-8'))\n",
    "  print()\n",
    "\n",
    "  print('> Examples in English:')\n",
    "  for en in en_examples.numpy():\n",
    "    print(en.decode('utf-8'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set up the tokenizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/models/ted_hrlr_translate_pt_en_converter.zip\n",
      "184801/184801 [==============================] - 0s 1us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "'./ted_hrlr_translate_pt_en_converter.zip'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'ted_hrlr_translate_pt_en_converter'\n",
    "tf.keras.utils.get_file(\n",
    "    f'{model_name}.zip',\n",
    "    f'https://storage.googleapis.com/download.tensorflow.org/models/{model_name}.zip',\n",
    "    cache_dir='.', cache_subdir='', extract=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "tokenizers = tf.saved_model.load(model_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "['detokenize',\n 'get_reserved_tokens',\n 'get_vocab_path',\n 'get_vocab_size',\n 'lookup',\n 'tokenize',\n 'tokenizer',\n 'vocab']"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item for item in dir(tokenizers.en) if not item.startswith('_')]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "array([b'and when you improve searchability , you actually take away the one advantage of print , which is serendipity .',\n       b'but what if it were active ?',\n       b\"but they did n't test for curiosity .\"], dtype=object)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_examples.numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> This is a batch of strings:\n",
      "and when you improve searchability , you actually take away the one advantage of print , which is serendipity .\n",
      "but what if it were active ?\n",
      "but they did n't test for curiosity .\n"
     ]
    }
   ],
   "source": [
    "print('> This is a batch of strings:')\n",
    "for en in en_examples.numpy():\n",
    "  print(en.decode('utf-8'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> This is a padded-batch of token IDs:\n",
      "[2, 72, 117, 79, 1259, 1491, 2362, 13, 79, 150, 184, 311, 71, 103, 2308, 74, 2679, 13, 148, 80, 55, 4840, 1434, 2423, 540, 15, 3]\n",
      "[2, 87, 90, 107, 76, 129, 1852, 30, 3]\n",
      "[2, 87, 83, 149, 50, 9, 56, 664, 85, 2512, 15, 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": "TensorShape([27])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded = tokenizers.en.tokenize(en_examples)\n",
    "\n",
    "print('> This is a padded-batch of token IDs:')\n",
    "for row in encoded.to_list():\n",
    "  print(row)\n",
    "\n",
    "encoded[0].shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(3,), dtype=int64, numpy=array([27,  9, 12])>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded.row_lengths()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> This is human-readable text:\n",
      "and when you improve searchability , you actually take away the one advantage of print , which is serendipity .\n",
      "but what if it were active ?\n",
      "but they did n ' t test for curiosity .\n"
     ]
    },
    {
     "data": {
      "text/plain": "20"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round_trip = tokenizers.en.detokenize(encoded)\n",
    "\n",
    "print('> This is human-readable text:')\n",
    "for line in round_trip.numpy():\n",
    "  print(line.decode('utf-8'))\n",
    "\n",
    "len(round_trip[0].numpy().decode(\"utf-8\").split(' '))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> This is the text split into tokens:\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tf.RaggedTensor [[b'[START]', b'and', b'when', b'you', b'improve', b'search', b'##ability',\n  b',', b'you', b'actually', b'take', b'away', b'the', b'one', b'advantage',\n  b'of', b'print', b',', b'which', b'is', b's', b'##ere', b'##nd', b'##ip',\n  b'##ity', b'.', b'[END]']                                                 ,\n [b'[START]', b'but', b'what', b'if', b'it', b'were', b'active', b'?',\n  b'[END]']                                                           ,\n [b'[START]', b'but', b'they', b'did', b'n', b\"'\", b't', b'test', b'for',\n  b'curiosity', b'.', b'[END]']                                          ]>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('> This is the text split into tokens:')\n",
    "tokens = tokenizers.en.lookup(encoded)\n",
    "tokens"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................."
     ]
    }
   ],
   "source": [
    "lengths = []\n",
    "\n",
    "for pt_examples, en_examples in train_examples.batch(1024):\n",
    "  pt_tokens = tokenizers.en.tokenize(pt_examples)\n",
    "  lengths.append(pt_tokens.row_lengths())\n",
    "\n",
    "  en_tokens = tokenizers.en.tokenize(en_examples)\n",
    "  lengths.append(en_tokens.row_lengths())\n",
    "  print('.', end='', flush=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "[<tf.Tensor: shape=(1024,), dtype=int64, numpy=array([45, 21, 23, ..., 21, 47, 35])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([27,  9, 12, ...,  9, 23, 28])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([ 32,  22,  34, ...,  39, 101,  36])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([17, 12, 20, ..., 30, 56, 13])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([48, 37, 27, ..., 92, 21, 49])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([29, 18, 15, ..., 53, 13, 29])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([72, 38, 35, ..., 20, 54, 13])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([38, 18, 16, ..., 11, 26, 11])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([ 15,  24,  51, ...,  27,  40, 117])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([10, 16, 24, ..., 20, 24, 71])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([28, 44, 26, ..., 95, 34, 32])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([17, 28, 14, ..., 39, 23, 22])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([35, 28, 43, ..., 71, 20, 18])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([15, 15, 26, ..., 34,  7, 10])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([ 32,  60,  25, ...,  37, 101,  31])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([18, 29, 15, ..., 22, 42, 21])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([16, 64, 26, ..., 38, 65, 41])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([11, 28, 12, ..., 15, 25, 24])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([21, 74, 30, ..., 32, 84, 71])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([12, 40, 10, ..., 20, 30, 34])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([56, 54, 38, ..., 34, 22, 23])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([45, 22, 21, ..., 14, 10, 16])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([ 30,  25,  56, ..., 114,  34,  75])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([16, 14, 30, ..., 47, 17, 34])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([26, 24, 28, ..., 17, 29, 30])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([14, 10, 13, ..., 10, 13, 13])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([19, 25, 65, ..., 39, 56, 75])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([10, 14, 33, ..., 15, 26, 39])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([48, 25, 23, ..., 65, 15,  8])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([24,  9, 10, ..., 37, 10,  5])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([50, 35, 56, ..., 33, 23, 58])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([30, 19, 20, ..., 15, 11, 23])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([15, 52, 11, ..., 43, 25, 37])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([10, 34, 10, ..., 25, 11, 21])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([52, 83, 31, ..., 33, 98, 31])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([30, 38, 19, ..., 15, 34, 16])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([ 30,  14,  24, ..., 103,  17,  55])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([17,  8, 34, ..., 51,  9, 37])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([36,  9,  8, ..., 55, 31, 37])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([19, 10,  5, ..., 28, 13, 17])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([ 39,  34,  19, ...,  43, 115,  26])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([19, 19, 10, ..., 29, 65,  9])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([51, 28, 57, ..., 48, 25, 41])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([35, 16, 27, ..., 24, 12, 18])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([52, 32, 80, ..., 14, 62, 44])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([27, 19, 42, ..., 11, 31, 20])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([34, 17, 49, ..., 12, 21, 25])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([16, 12, 30, ...,  8, 11, 11])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([ 68, 119,  19, ...,  11,  21,  35])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([31, 54, 11, ..., 12, 12, 25])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([38, 25, 14, ..., 54, 21, 40])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([25, 10,  6, ..., 24, 10, 27])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([ 57,  41,  14, ...,  26,  92, 198])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([ 36,  20,  12, ...,  12,  40, 103])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([25, 30, 40, ..., 35, 36, 30])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([10, 22, 21, ..., 22, 17, 13])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([63, 26, 23, ..., 98, 32, 42])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([35, 16, 12, ..., 52, 14, 23])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([15, 65, 23, ..., 63, 47, 21])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([ 9, 34, 15, ..., 40, 24, 15])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([12, 21, 37, ..., 28, 16, 25])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([10,  8, 16, ..., 11,  9, 12])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([99, 82, 41, ..., 33, 59, 15])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([41, 46, 22, ..., 13, 25,  8])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([ 15,  25,  64, ..., 158,  25, 103])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([10, 14, 44, ..., 78, 13, 40])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([28, 13, 78, ..., 25, 39, 12])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([19,  9, 31, ..., 12, 22, 10])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([20,  9, 90, ..., 21, 66, 17])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([11,  5, 34, ..., 12, 27, 10])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([127,  28,  35, ...,  75,  43,  14])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([87, 16, 12, ..., 34, 18, 13])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([  8,  27,  90, ...,  48,  10, 227])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([  5,  19,  38, ...,  23,   4, 130])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([65, 69, 37, ..., 13,  9, 11])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([32, 36, 19, ..., 13,  5, 10])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([27, 37, 21, ..., 49, 15, 23])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([20, 17, 11, ..., 28, 13, 15])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([11, 24, 75, ..., 40,  9, 15])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([ 8, 12, 53, ..., 21,  8, 10])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([21, 55, 24, ..., 36, 34, 36])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([15, 27, 10, ..., 24, 19, 23])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([46, 38, 28, ..., 56, 53, 40])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([27, 27, 11, ..., 26, 24, 21])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([ 42, 241,  50, ...,  64,  40,  54])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([ 15, 117,  23, ...,  31,  24,  21])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([63, 29, 29, ..., 49, 24, 63])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([24,  8, 19, ..., 33, 13, 32])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([43, 27, 28, ..., 76, 51, 46])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([33, 13, 11, ..., 43, 24, 16])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([63, 28, 21, ..., 21, 46, 45])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([24, 16, 12, ..., 10, 23, 26])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([76, 26, 52, ..., 29, 53, 15])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([40, 19, 23, ..., 19, 20, 10])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([106,  15,  14, ...,  73,  25,  56])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([44,  9,  9, ..., 32, 18, 32])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([44, 30, 33, ..., 52, 42, 38])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([18, 13, 21, ..., 27, 16, 21])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([11, 31, 12, ..., 98, 19, 24])>,\n <tf.Tensor: shape=(1024,), dtype=int64, numpy=array([ 7, 19, 11, ..., 73,  9, 14])>,\n <tf.Tensor: shape=(585,), dtype=int64, numpy=\n array([ 25,  22,  11,  26,  34,  34,   8,  63,  15,  37,  71,  67,  18,\n         11,  53, 109,  84, 143,  20,  17,  30,  30,  19,  10,  46,  30,\n         24,  23,  22,  60, 153,  19,  69,  20,  18,  20,  40, 113,  54,\n          9,  20,  15,  43,  48,  55,  34,  55,  38,  56,  14,  24,  20,\n         45,  28,  32,  26,  18,  15,  40,  57,  32,  28,  39,  13,  30,\n         89,  18,  48,  57,  40, 128,  25,  36,  70,  94,  71,  85,  29,\n        148,  48,  39,  50,  33, 111,  19,  31,  19,  45,  34,  29, 100,\n         30,  28,  25,  66,  76,  36,  67,  18,  55,  50,  35,  85,  17,\n         51, 130,  19,  14,  33,  23,  84, 108,  34,  24,   9,  23,  18,\n         17,  32,  67,  21, 135,  24,  53,  57,  78,  43,  30,  36,  22,\n         54,  24,  34,  62,  65,  63,  10,  87, 151,  16,  53,  41,   9,\n         45, 138,  29,  67, 122,  31,  33,  27,  53,  17, 138,  54,  81,\n         33,  35,  81,  32,  46,  29,  25,  13,  55,  92,   9,  29,  48,\n         54,  25,  75,  91, 109,  56,  63,  54,   9,  65,  15,  39,  39,\n         23,  23,  78,  21,  60,  66,  65,  30,  22,  27,  51,  29,  31,\n         27,  42,  49,  31,  19,  13,  71,  25,  23,  81,  12,  88,  16,\n         99,  18,  31,  20, 106,  21,  11,  29,  71,  21,  47,  20,  19,\n         72,  14,  34,  58,  18,   9,  15, 248,  67,  50,  94,  22, 150,\n         49,  14,  37,  80,  47,  89,  29,  60,  30,  98,  24,  91,   9,\n         44,  26, 131,  43,  50,  10,  40,  19,  87,  58,  20,  17,  27,\n          8,  35,  15,  67,  33,  28,  11,  39,  27,  18,  39,  45,  37,\n         86,  27, 106,  36,  26,  20,  53,  31,  41,  24,  24,  21,  51,\n         18,  55,  10,  29, 178,  65,  33,  24,  99,  44,  91,  18,  24,\n         41,  28,  18,  37,  83,  23,  73,  21,  27,  35,  87,   7,  33,\n         79,  28,  29,  42,  75,  31,  28,  26,  17, 211,  19,  31,  94,\n         36,  26,  43,  24,  50,  40,  20,  42,  39, 169,   8,  53,  18,\n         37,  84,  26,  90,  78,  18,  53,  25,  28,  40,  16,  36,  24,\n         44,  32,  22,  59, 140,  57,  62,  29,  49,  48,  45,  20,  45,\n         47,  47,  57, 136,  29,  18,  62,  70,  14,  45,  38,  49,  74,\n         37,  23,  16,  34,  38,  19,  18,  16,  88,  32,  78,  49,  88,\n         26,  44,  16,  31,  30,  52, 137, 114,  33,  26,  22,  24, 172,\n         32,  28,  90,  15,  27,  91, 108,  52,   9,  11,  45,  24,  37,\n         99,  19,  24, 107,  48,  70,  22,  85, 111, 178,  30,  38, 118,\n         85,  10,  33,   8,  22,  29,  19,  28,  21, 177,  24,  55,  30,\n         17, 135,  27,  22,  31,  34,  20,  33,  34, 142,  23,  75,  45,\n         32,  21,  21,  15,  31,  32,  30,  10, 158, 148,   9,  45,  19,\n         55,  24,  47,  66,  16,  86,  55,  48,  53,  19,  21,  39,  22,\n         15,  20,  84,  29,  38,  77,  28,  79, 187,  57,  23,  61,  23,\n         74,  41,  55,  32,  79,  32,  30,  54,   7,  50,  16,  21,  25,\n         51,  31,  14,  16,  51,  35,  36,  16,  50,  56,  59,  47,  34,\n        140,  37,  38,  20,  56,  46,  65,  58,   8,  62,  10,  71,  17,\n         25,  28, 119,  48,  20, 104,  20,   7,  19, 140,  25,  61, 128,\n         94,  22,  49,  86,  45,  19,  80,  41,  32,  81,  92,  26,  29,\n         57,  18,  22,  16,  16,  28,  18,  83,  55,  15,  35,  18,  42,\n         25,  30,  53,  32,  69,  23,  27,  25,  45,  57, 102,  16,  46])>,\n <tf.Tensor: shape=(585,), dtype=int64, numpy=\n array([ 16,  12,  10,  17,  18,  15,   5,  27,   8,  18,  38,  29,  11,\n          6,  30,  54,  46,  75,  12,  10,  16,  13,  11,   5,  28,  13,\n         14,  14,  12,  32,  63,   7,  39,   8,  15,  18,  27,  54,  26,\n          5,   8,  10,  25,  21,  29,  16,  32,  17,  29,   8,  13,   9,\n         26,  13,  21,  17,  14,   7,  23,  31,  16,  16,  20,  14,  17,\n         51,  10,  27,  25,  15,  73,  16,  15,  34,  49,  33,  46,  19,\n         56,  26,  24,  21,  14,  41,  14,  19,   8,  22,  19,  14,  35,\n         15,  16,  17,  30,  41,  16,  36,  13,  28,  36,  16,  58,   8,\n         24,  64,  12,  11,  14,  10,  59,  51,  21,  15,   6,  13,  10,\n         10,  15,  29,  15,  86,  15,  27,  33,  43,  22,  18,  16,  10,\n         36,  12,  19,  48,  31,  27,   6,  46,  71,  11,  24,  24,   5,\n         22,  73,  19,  29,  58,  18,  17,  18,  30,  11,  59,  29,  42,\n         19,  19,  40,  15,  28,  21,   8,  13,  34,  48,   6,  18,  23,\n         27,  10,  34,  44,  53,  28,  32,  46,   5,  23,   9,  15,  25,\n         18,  12,  50,  14,  38,  29,  38,  15,  17,   9,  30,  16,  24,\n         13,  24,  26,  14,  10,  11,  40,  16,  17,  43,   8,  48,   6,\n         59,  13,  19,  15,  45,  10,   7,  21,  37,  11,  34,  16,  14,\n         41,   8,  13,  30,   9,   5,  11, 134,  30,  27,  42,  17,  85,\n         28,   7,  26,  38,  28,  41,  15,  32,  12,  59,  16,  46,   5,\n         22,  14,  65,  18,  25,   7,  17,  12,  54,  25,  12,  14,  15,\n          5,  18,   8,  27,  17,  18,   9,  14,  15,   9,  20,  35,  17,\n         45,  13,  37,  21,  14,  24,  28,  16,  22,  12,  19,   9,  33,\n         13,  29,   8,  19,  83,  28,  15,  18,  54,  25,  41,   8,  13,\n         29,  16,  15,  17,  61,  13,  28,   9,  15,  18,  35,   6,  16,\n         43,  16,  20,  24,  43,  16,  19,  16,   9, 123,  11,  17,  43,\n         17,  33,  22,  17,  29,  11,  13,  27,  22,  90,   5,  31,   7,\n         20,  47,  10,  62,  34,   9,  28,  16,  17,  16,  21,  15,  15,\n         22,  17,  13,  29,  60,  23,  28,  12,  29,  19,  22,  15,  25,\n         26,  30,  29,  58,  22,  11,  35,  41,  12,  25,  21,  24,  33,\n         27,  12,  17,  16,  20,   9,  10,  10,  46,  18,  42,  21,  49,\n         13,  23,  12,  16,  20,  21,  64,  50,  19,  17,   9,  11,  94,\n         16,  16,  41,  12,  13,  51,  75,  19,   8,   8,  30,  15,  23,\n         45,  11,  16,  40,  22,  33,  10,  58,  53,  88,  15,  27,  59,\n         44,   6,  16,   5,  13,  11,  16,  20,  13,  73,  14,  21,  12,\n         12,  61,  15,  13,  15,  19,  12,  20,  13,  89,  10,  39,  26,\n         16,  11,   8,  10,  19,  20,  19,   5,  88,  65,   5,  20,   7,\n         32,  15,  19,  32,  11,  43,  27,  20,  32,  11,  14,  24,  13,\n         10,  12,  31,  15,  18,  42,  13,  50,  75,  37,  12,  31,  11,\n         29,  18,  33,  19,  32,  14,  13,  27,   7,  25,  11,  11,  11,\n         18,  16,   7,   9,  16,  14,  20,   8,  26,  26,  23,  18,  20,\n         72,  16,  15,  14,  18,  21,  36,  35,   4,  24,   7,  25,  11,\n         15,  19,  50,  33,  13,  55,  12,   4,  12,  75,  13,  28,  75,\n         47,  14,  19,  30,  21,  13,  29,  22,  18,  36,  39,  15,  16,\n         27,  10,  11,   8,  10,  21,  15,  34,  28,   7,  16,   9,  17,\n         11,  16,  41,  16,  31,  12,  15,  12,  26,  30,  49,  16,  18])>]"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_lengths = np.concatenate(lengths)\n",
    "\n",
    "plt.hist(all_lengths, np.linspace(0, 500, 101))\n",
    "plt.ylim(plt.ylim())\n",
    "max_length = max(all_lengths)\n",
    "plt.plot([max_length, max_length], plt.ylim())\n",
    "plt.title(f'Maximum tokens per example: {max_length}');"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Set up a data pipeline with tf.data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "MAX_TOKENS=128\n",
    "def prepare_batch(pt, en):\n",
    "    pt = tokenizers.pt.tokenize(pt)      # Output is ragged.\n",
    "    pt = pt[:, :MAX_TOKENS]    # Trim to MAX_TOKENS.\n",
    "    pt = pt.to_tensor()  # Convert to 0-padded dense Tensor\n",
    "\n",
    "    en = tokenizers.en.tokenize(en)\n",
    "    en = en[:, :(MAX_TOKENS+1)]\n",
    "    en_inputs = en[:, :-1].to_tensor()  # Drop the [END] tokens\n",
    "    en_labels = en[:, 1:].to_tensor()   # Drop the [START] tokens\n",
    "\n",
    "    return (pt, en_inputs), en_labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
