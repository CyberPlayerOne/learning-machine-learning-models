{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Neural machine translation with a Transformer and Keras\n",
    "https://www.tensorflow.org/text/tutorials/transformer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# # Install the most re version of TensorFlow to use the improved\n",
    "# # masking support for `tf.keras.layers.MultiHeadAttention`.\n",
    "# apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2\n",
    "# pip uninstall -y -q tensorflow keras tensorflow-estimator tensorflow-text\n",
    "# pip install -q tensorflow_datasets\n",
    "# pip install -q -U tensorflow-text tensorflow"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-05 10:20:11.682837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-05 10:20:21.244843: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-01-05 10:20:43.346091: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-01-05 10:20:43.346612: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-01-05 10:20:43.346648: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data handling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Download the Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-05 10:24:08.452997: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 10:24:09.045293: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 10:24:09.046792: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 10:24:09.079715: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-05 10:24:09.085584: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 10:24:09.087130: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 10:24:09.088502: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 10:24:14.170900: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 10:24:14.177946: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 10:24:14.179563: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 10:24:14.181319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6481 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en',\n",
    "                               with_info=True,\n",
    "                               as_supervised=True)\n",
    "\n",
    "train_examples, val_examples = examples['train'], examples['validation']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "tfds.core.DatasetInfo(\n    name='ted_hrlr_translate',\n    full_name='ted_hrlr_translate/pt_to_en/1.0.0',\n    description=\"\"\"\n    Data sets derived from TED talk transcripts for comparing similar language pairs\n    where one is high resource and the other is low resource.\n    \"\"\",\n    config_description=\"\"\"\n    Translation dataset from pt to en in plain text.\n    \"\"\",\n    homepage='https://github.com/neulab/word-embeddings-for-nmt',\n    data_path='~/tensorflow_datasets/ted_hrlr_translate/pt_to_en/1.0.0',\n    file_format=tfrecord,\n    download_size=124.94 MiB,\n    dataset_size=10.89 MiB,\n    features=Translation({\n        'en': Text(shape=(), dtype=tf.string),\n        'pt': Text(shape=(), dtype=tf.string),\n    }),\n    supervised_keys=('pt', 'en'),\n    disable_shuffling=False,\n    splits={\n        'test': <SplitInfo num_examples=1803, num_shards=1>,\n        'train': <SplitInfo num_examples=51785, num_shards=1>,\n        'validation': <SplitInfo num_examples=1193, num_shards=1>,\n    },\n    citation=\"\"\"@inproceedings{Ye2018WordEmbeddings,\n      author  = {Ye, Qi and Devendra, Sachan and Matthieu, Felix and Sarguna, Padmanabhan and Graham, Neubig},\n      title   = {When and Why are pre-trained word embeddings useful for Neural Machine Translation},\n      booktitle = {HLT-NAACL},\n      year    = {2018},\n      }\"\"\",\n)"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Examples in Portuguese:\n",
      "e quando melhoramos a procura , tiramos a única vantagem da impressão , que é a serendipidade .\n",
      "mas e se estes fatores fossem ativos ?\n",
      "mas eles não tinham a curiosidade de me testar .\n",
      "\n",
      "> Examples in English:\n",
      "and when you improve searchability , you actually take away the one advantage of print , which is serendipity .\n",
      "but what if it were active ?\n",
      "but they did n't test for curiosity .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-05 10:25:17.384947: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for pt_examples, en_examples in train_examples.batch(3).take(1):\n",
    "  print('> Examples in Portuguese:')\n",
    "  for pt in pt_examples.numpy():\n",
    "    print(pt.decode('utf-8'))\n",
    "  print()\n",
    "\n",
    "  print('> Examples in English:')\n",
    "  for en in en_examples.numpy():\n",
    "    print(en.decode('utf-8'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set up the tokenizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "'./ted_hrlr_translate_pt_en_converter.zip'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'ted_hrlr_translate_pt_en_converter'\n",
    "tf.keras.utils.get_file(\n",
    "    f'{model_name}.zip',\n",
    "    f'https://storage.googleapis.com/download.tensorflow.org/models/{model_name}.zip',\n",
    "    cache_dir='.', cache_subdir='', extract=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "tokenizers = tf.saved_model.load(model_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/downloads\r\n",
      " Makefile   ted_hrlr_translate_pt_en_converter\t    '~'\r\n",
      " mlruns     ted_hrlr_translate_pt_en_converter.zip\r\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!ls"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "['detokenize',\n 'get_reserved_tokens',\n 'get_vocab_path',\n 'get_vocab_size',\n 'lookup',\n 'tokenize',\n 'tokenizer',\n 'vocab']"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item for item in dir(tokenizers.en) if not item.startswith('_')]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> This is a batch of strings:\n",
      "and when you improve searchability , you actually take away the one advantage of print , which is serendipity .\n",
      "but what if it were active ?\n",
      "but they did n't test for curiosity .\n"
     ]
    }
   ],
   "source": [
    "print('> This is a batch of strings:')\n",
    "for en in en_examples.numpy():\n",
    "  print(en.decode('utf-8'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> This is a padded-batch of token IDs:\n",
      "[2, 72, 117, 79, 1259, 1491, 2362, 13, 79, 150, 184, 311, 71, 103, 2308, 74, 2679, 13, 148, 80, 55, 4840, 1434, 2423, 540, 15, 3]\n",
      "[2, 87, 90, 107, 76, 129, 1852, 30, 3]\n",
      "[2, 87, 83, 149, 50, 9, 56, 664, 85, 2512, 15, 3]\n"
     ]
    }
   ],
   "source": [
    "encoded = tokenizers.en.tokenize(en_examples)\n",
    "\n",
    "print('> This is a padded-batch of token IDs:')\n",
    "for row in encoded.to_list():\n",
    "  print(row)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> This is human-readable text:\n",
      "and when you improve searchability , you actually take away the one advantage of print , which is serendipity .\n",
      "but what if it were active ?\n",
      "but they did n ' t test for curiosity .\n"
     ]
    }
   ],
   "source": [
    "round_trip = tokenizers.en.detokenize(encoded)\n",
    "\n",
    "print('> This is human-readable text:')\n",
    "for line in round_trip.numpy():\n",
    "  print(line.decode('utf-8'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> This is the text split into tokens:\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tf.RaggedTensor [[b'[START]', b'and', b'when', b'you', b'improve', b'search', b'##ability',\n  b',', b'you', b'actually', b'take', b'away', b'the', b'one', b'advantage',\n  b'of', b'print', b',', b'which', b'is', b's', b'##ere', b'##nd', b'##ip',\n  b'##ity', b'.', b'[END]']                                                 ,\n [b'[START]', b'but', b'what', b'if', b'it', b'were', b'active', b'?',\n  b'[END]']                                                           ,\n [b'[START]', b'but', b'they', b'did', b'n', b\"'\", b't', b'test', b'for',\n  b'curiosity', b'.', b'[END]']                                          ]>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('> This is the text split into tokens:')\n",
    "tokens = tokenizers.en.lookup(encoded)\n",
    "tokens"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................."
     ]
    }
   ],
   "source": [
    "lengths = []\n",
    "\n",
    "for pt_examples, en_examples in train_examples.batch(1024):\n",
    "  pt_tokens = tokenizers.pt.tokenize(pt_examples)\n",
    "  lengths.append(pt_tokens.row_lengths())\n",
    "\n",
    "  en_tokens = tokenizers.en.tokenize(en_examples)\n",
    "  lengths.append(en_tokens.row_lengths())\n",
    "  print('.', end='', flush=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_lengths = np.concatenate(lengths)\n",
    "\n",
    "plt.hist(all_lengths, np.linspace(0, 500, 101))\n",
    "plt.ylim(plt.ylim())\n",
    "max_length = max(all_lengths)\n",
    "plt.plot([max_length, max_length], plt.ylim())\n",
    "plt.title(f'Maximum tokens per example: {max_length}');"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set up a data pipeline with tf.data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "MAX_TOKENS=128\n",
    "def prepare_batch(pt, en):\n",
    "    pt = tokenizers.pt.tokenize(pt)      # Output is ragged.\n",
    "    pt = pt[:, :MAX_TOKENS]    # Trim to MAX_TOKENS.\n",
    "    pt = pt.to_tensor()  # Convert to 0-padded dense Tensor\n",
    "\n",
    "    en = tokenizers.en.tokenize(en)\n",
    "    en = en[:, :(MAX_TOKENS+1)]\n",
    "    en_inputs = en[:, :-1].to_tensor()  # Drop the [END] tokens\n",
    "    en_labels = en[:, 1:].to_tensor()   # Drop the [START] tokens\n",
    "\n",
    "    return (pt, en_inputs), en_labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def make_batches(ds):\n",
    "  return (\n",
    "      ds\n",
    "      .shuffle(BUFFER_SIZE)\n",
    "      .batch(BATCH_SIZE)\n",
    "      .map(prepare_batch, tf.data.AUTOTUNE)\n",
    "      .prefetch(buffer_size=tf.data.AUTOTUNE))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test the Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# Create training and validation set batches.\n",
    "train_batches = make_batches(train_examples)\n",
    "val_batches = make_batches(val_examples)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 122)\n",
      "(64, 90)\n",
      "(64, 90)\n"
     ]
    }
   ],
   "source": [
    "for (pt, en), en_labels in train_batches.take(1):\n",
    "  break\n",
    "\n",
    "print(pt.shape)\n",
    "print(en.shape)\n",
    "print(en_labels.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([   2   72  110   13   46  840 1225   80  111 1178], shape=(10,), dtype=int64)\n",
      "tf.Tensor([  72  110   13   46  840 1225   80  111 1178   13], shape=(10,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(en[0][:10])\n",
    "print(en_labels[0][:10])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define the components"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
